{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## This notebook can be used to save the dense representation of a DeepSVG model to a pkl file\n",
    "\n",
    "It should be run using the environment created from the requirements.txt file in the SVGRepresentation folder.\n",
    "\n",
    "The following code expects the folder 'SVG_Data' to be in the same directory as the cloned project repository.\n",
    "```\n",
    "parent/\n",
    "    ├── SVG_Data\n",
    "    └── SVG_LogoGenerator\n",
    "```\n",
    "If this is not the case on your machine make sure to\n",
    "* set the correct path to the SVG_Data folder here:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "datafolder = \"../../../SVG_Data/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../deepsvg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepsvg.svglib.svg import SVG\n",
    "from deepsvg import utils\n",
    "from deepsvg.difflib.tensor import SVGTensor\n",
    "from deepsvg.svglib.geom import Bbox\n",
    "from deepsvg.svgtensor_dataset import load_dataset\n",
    "from deepsvg.utils.utils import batchify\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda:0\"if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Helper functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svg(filename):\n",
    "    svg = SVG.load_svg(filename)\n",
    "    svg = dataset.simplify(svg)\n",
    "    svg = dataset.preprocess(svg)\n",
    "    return svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data):\n",
    "    model_args = batchify((data[key] for key in cfg.model_args), device)\n",
    "    with torch.no_grad():\n",
    "        z = model(*model_args, encode_mode=True)\n",
    "        return z\n",
    "\n",
    "def encode_icon(idx):\n",
    "    data = dataset.get(id=idx, random_aug=False)\n",
    "    return encode(data)\n",
    "    \n",
    "def encode_svg(svg):\n",
    "    data = dataset.get(svg=svg)\n",
    "    return encode(data)\n",
    "\n",
    "def decode(z, do_display=True, return_svg=False, return_png=False):\n",
    "    commands_y, args_y = model.greedy_sample(z=z)\n",
    "    tensor_pred = SVGTensor.from_cmd_args(commands_y[0].cpu(), args_y[0].cpu())\n",
    "    svg_path_sample = SVG.from_tensor(tensor_pred.data, viewbox=Bbox(256), allow_empty=True).normalize().split_paths().set_color(\"random\")\n",
    "    \n",
    "    if return_svg:\n",
    "        return svg_path_sample\n",
    "    \n",
    "    return svg_path_sample.draw(do_display=do_display, return_png=return_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Load the trained model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = os.path.join(datafolder, \"deepsvg_training_logs/16g-62seq-128c-256z-deepsvg-icons/models/deepsvg/hierarchical_ordered_new_data/best.pth.tar\")\n",
    "from configs.deepsvg.hierarchical_ordered_new_data import Config\n",
    "\n",
    "cfg = Config()\n",
    "model = cfg.make_model().to(device)\n",
    "utils.load_model(pretrained_path, model)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(cfg)\n",
    "meta_file = pd.read_csv(os.path.join(datafolder, \"data_for_training_deepsvg_model/icons_meta.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Inspect an encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg1_latent_rep = encode_icon(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 1, 256])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svg1_latent_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 0.0787,  0.1094,  0.1121, -0.1543,  0.0174,  0.0748,  0.0833,\n            0.0980,  0.0094, -0.2035,  0.0509,  0.0371,  0.1414,  0.0367,\n           -0.1606, -0.1004, -0.1370, -0.2025,  0.0081, -0.1318,  0.0534,\n            0.0733,  0.2417,  0.0075,  0.1242, -0.0746,  0.0848, -0.1136,\n            0.0408, -0.0566, -0.0141,  0.0060,  0.0247, -0.0285,  0.0709,\n            0.0654,  0.0382, -0.1433,  0.1311,  0.0380, -0.1332,  0.1894,\n           -0.2546, -0.2028, -0.0363,  0.0416,  0.3167, -0.2446, -0.1335,\n            0.0606,  0.1560,  0.0377, -0.2322,  0.0583,  0.0247, -0.0560,\n           -0.0761, -0.0184, -0.0685,  0.1575,  0.1370, -0.2069,  0.4353,\n            0.0899, -0.0268, -0.1928,  0.1368, -0.1049,  0.1024, -0.1501,\n            0.0724, -0.1745,  0.0493,  0.0780, -0.0518,  0.2505,  0.1303,\n            0.0711,  0.0944,  0.0413,  0.0097,  0.1422, -0.0526, -0.0419,\n           -0.3117,  0.0707, -0.1062,  0.0531,  0.1219, -0.0082, -0.1881,\n            0.1019, -0.1973, -0.1224, -0.0685, -0.1277, -0.1620, -0.0483,\n            0.0558,  0.1291,  0.0886, -0.0091,  0.0054,  0.1638, -0.1686,\n           -0.0218, -0.2611, -0.1097, -0.2356,  0.0421, -0.0020,  0.0560,\n            0.0377,  0.1003,  0.0385,  0.0145,  0.0136,  0.1148, -0.0330,\n            0.0403,  0.0545, -0.0337,  0.0223, -0.1455,  0.0527,  0.0854,\n           -0.0624,  0.1005,  0.0396, -0.0439,  0.0669, -0.1163,  0.2038,\n            0.1575, -0.2400, -0.0640, -0.0663, -0.1436,  0.0367, -0.1488,\n           -0.0382,  0.4323,  0.0642,  0.0976, -0.0973,  0.0151, -0.0231,\n           -0.0904,  0.1132,  0.0245,  0.3670, -0.0928,  0.2709,  0.2448,\n            0.1329,  0.0397,  0.1581, -0.1971, -0.1003, -0.0958,  0.0485,\n           -0.0108, -0.1888, -0.0262,  0.0911,  0.0818,  0.0109,  0.1362,\n            0.0807, -0.0348,  0.0214,  0.0066,  0.1062,  0.0102, -0.1121,\n            0.0294, -0.0761, -0.0530,  0.1287, -0.1269, -0.0642,  0.1006,\n           -0.1168,  0.1153, -0.0510, -0.1019, -0.0199,  0.0479,  0.0243,\n            0.0756,  0.0054,  0.1036,  0.0930,  0.0851, -0.1976, -0.0528,\n            0.0027,  0.3089,  0.0822,  0.0267, -0.0923,  0.0205,  0.1457,\n           -0.1546, -0.2171, -0.0871,  0.0608, -0.0115,  0.0779,  0.1627,\n           -0.1105,  0.1585, -0.0470,  0.0877, -0.1123, -0.1804,  0.1934,\n            0.1703, -0.0360,  0.1002, -0.1037, -0.1098,  0.1103,  0.0223,\n            0.0439, -0.1036,  0.0525,  0.1101, -0.0159,  0.0334,  0.1766,\n            0.0882, -0.0837,  0.1149, -0.1786, -0.4700,  0.0763, -0.1783,\n            0.0565,  0.0775, -0.0059,  0.1568, -0.0485,  0.1263, -0.0305,\n           -0.3158,  0.1295, -0.0848, -0.1492, -0.0836,  0.0966,  0.0999,\n            0.2174,  0.1025,  0.1425,  0.0267]]]], device='cuda:0')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svg1_latent_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.SVG object>",
      "image/svg+xml": "<svg height=\"200px\" viewBox=\"0.0 0.0 24.0 24.0\" width=\"200px\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M10.21875 7.125 L10.125 7.125 C11.25 7.21875 12.1875 7.5 12.84375 8.34375 C13.59375 9.46875 13.59375 10.6875 13.125 11.625 C12.5625 12.84375 11.53125 13.40625 10.21875 13.40625 C8.90625 13.40625 8.0625 12.65625 7.3125 11.625 C6.9375 10.59375 6.84375 9.46875 7.59375 8.4375 C8.34375 7.40625 9.1875 7.21875 10.125 7.03125 L10.125 7.125\" fill=\"none\" filling=\"0\" stroke=\"deepskyblue\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M6.28125 7.78125 L6.375 7.78125 C7.03125 7.875 7.59375 7.96875 7.875 8.34375 L8.34375 9.375 C7.6875 9.84375 7.78125 10.40625 7.59375 10.875 C7.6875 11.25 7.78125 11.71875 7.78125 12.0 C7.21875 12.09375 6.9375 12.375 6.84375 12.65625 C5.625 12.65625 4.96875 12.09375 4.59375 11.71875 C3.9375 10.96875 3.75 9.84375 4.21875 9.0 C4.78125 8.15625 5.4375 7.875 6.28125 7.6875 L6.28125 7.78125\" fill=\"none\" filling=\"0\" stroke=\"lime\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M14.15625 7.78125 L14.15625 7.78125 C15.09375 7.875 15.84375 8.15625 16.3125 9.0 C16.875 9.84375 16.59375 11.0625 16.03125 11.625 C15.46875 12.375 14.625 12.5625 13.78125 12.375 C13.21875 12.5625 12.84375 12.09375 12.375 11.71875 C12.28125 11.4375 12.28125 11.15625 12.375 10.78125 C12.28125 10.40625 12.09375 10.125 12.0 9.84375 L12.46875 8.625 C12.9375 7.96875 13.40625 7.78125 14.15625 7.6875 L14.25 7.6875\" fill=\"none\" filling=\"0\" stroke=\"deeppink\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M10.21875 8.15625 L10.125 8.15625 C10.875 8.25 11.53125 8.34375 11.90625 8.625 C12.75 9.5625 12.5625 10.5 12.1875 11.15625 C11.53125 11.8125 10.96875 12.1875 10.21875 12.375 C9.46875 12.1875 8.90625 11.90625 8.625 11.25 C7.96875 10.40625 7.875 9.46875 8.53125 8.8125 C9.09375 8.34375 9.5625 8.25 10.21875 8.15625 L10.21875 8.15625\" fill=\"none\" filling=\"0\" stroke=\"gold\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M8.90625 8.625 L9.5625 8.71875 C9.5625 8.8125 9.75 8.90625 9.75 9.0 C9.75 9.09375 9.5625 9.1875 9.5625 9.28125 L8.90625 9.28125 C8.8125 9.09375 8.53125 9.09375 8.53125 9.0 C8.71875 8.90625 8.90625 8.71875 8.90625 8.625 L8.90625 8.625\" fill=\"none\" filling=\"0\" stroke=\"coral\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M11.15625 8.625 L11.8125 8.625 C11.90625 8.8125 12.0 8.90625 12.0 9.0 C11.90625 9.09375 11.90625 9.1875 11.8125 9.28125 L11.0625 9.28125 C10.96875 9.09375 10.6875 9.09375 10.875 8.90625 C10.875 8.90625 11.0625 8.8125 11.15625 8.625 L10.96875 8.625\" fill=\"none\" filling=\"0\" stroke=\"darkviolet\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M9.0 9.75 L9.0 9.75 C9.09375 9.84375 9.28125 9.84375 9.375 9.9375 L9.375 9.9375 C9.46875 9.9375 9.65625 9.84375 9.65625 9.9375 C9.65625 10.125 9.75 10.21875 9.65625 10.40625 C10.21875 10.6875 9.46875 10.96875 9.09375 10.875 C8.8125 10.5 8.625 10.40625 8.71875 10.125 C8.71875 10.125 8.71875 9.9375 8.90625 9.75 L9.0 9.75\" fill=\"none\" filling=\"0\" stroke=\"royalblue\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M11.53125 9.75 L11.53125 9.75 C11.53125 9.84375 11.90625 9.84375 12.0 9.9375 L12.0 9.9375 C11.90625 10.125 11.90625 10.125 11.90625 10.125 L11.8125 10.40625 C11.90625 10.5 11.34375 10.78125 11.15625 10.5 C11.25 10.40625 11.0625 10.40625 11.15625 10.21875 C11.0625 10.03125 11.25 9.84375 11.4375 9.75 L11.4375 9.75\" fill=\"none\" filling=\"0\" stroke=\"darkmagenta\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M10.125 10.96875 L10.5 10.96875 C10.78125 11.53125 10.6875 11.90625 10.5 11.90625 C9.75 12.28125 9.65625 11.625 9.84375 11.25 L10.125 10.96875\" fill=\"none\" filling=\"0\" stroke=\"teal\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M9.375 12.5625 L9.5625 12.5625 C9.09375 13.6875 8.90625 14.90625 8.0625 15.09375 C7.125 15.09375 6.5625 14.90625 6.375 14.4375 C6.09375 15.0 6.09375 13.78125 6.375 13.3125 C7.21875 12.9375 7.78125 12.75 8.4375 12.5625 L8.8125 12.5625\" fill=\"none\" filling=\"0\" stroke=\"gold\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M10.40625 12.09375 L10.40625 12.09375 C11.0625 12.28125 11.53125 12.5625 11.90625 12.84375 C13.21875 13.6875 13.03125 14.8125 12.5625 15.5625 C11.90625 16.59375 10.875 17.0625 9.84375 16.875 C9.09375 16.59375 8.34375 15.65625 8.0625 14.71875 C7.6875 14.0625 8.15625 13.3125 8.8125 12.75 C8.90625 12.5625 9.28125 12.375 9.84375 12.28125 L9.84375 12.375 C9.5625 12.75 9.65625 12.9375 9.5625 13.03125 C9.09375 15.46875 9.09375 15.84375 9.5625 15.9375 C10.78125 15.46875 11.15625 15.46875 11.34375 14.90625 C11.53125 14.625 11.53125 14.4375 11.4375 13.78125 C11.4375 13.40625 11.15625 12.9375 10.5 12.375 L10.40625 12.0\" fill=\"none\" filling=\"0\" stroke=\"green\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M11.4375 12.5625 L11.53125 12.5625 C12.0 12.5625 12.65625 12.65625 13.125 13.03125 C14.15625 13.78125 13.6875 14.8125 13.03125 15.1875 C12.9375 15.28125 12.09375 15.0 11.4375 14.34375 C11.25 13.5 11.4375 12.9375 11.4375 12.75 L11.53125 12.75\" fill=\"none\" filling=\"0\" stroke=\"maroon\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M9.09375 16.78125 L9.09375 16.78125 C9.375 16.78125 9.65625 17.0625 9.5625 17.4375 C9.75 17.8125 9.65625 18.5625 9.0 18.28125 C8.25 18.5625 7.875 17.625 8.0625 17.15625 C8.53125 16.96875 8.71875 16.96875 9.09375 16.78125 L9.09375 16.59375\" fill=\"none\" filling=\"0\" stroke=\"aqua\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M11.90625 16.3125 L11.90625 16.3125 C12.375 16.3125 12.46875 16.78125 12.65625 16.96875 C13.03125 17.4375 12.46875 18.5625 11.90625 18.0 C11.25 18.09375 10.96875 17.34375 11.15625 16.78125 C11.25 16.59375 11.4375 16.59375 11.8125 16.3125 L11.90625 16.3125\" fill=\"none\" filling=\"0\" stroke=\"grey\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M21.75 21.75 M21.75 21.75\" fill=\"none\" filling=\"0\" stroke=\"steelblue\" stroke-opacity=\"1.0\" stroke-width=\".3\"/>\n<path d=\"M21.75 21.75 M21.75 21.75\" fill=\"none\" filling=\"0\" stroke=\"lime\" stroke-opacity=\"1.0\" stroke-width=\".3\"/></svg>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decode(svg1_latent_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Create pkl of list of all encodings for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58669 relevant samples\n"
     ]
    }
   ],
   "source": [
    "relevant_samples = meta_file[(meta_file.total_len <= 128) & (meta_file.nb_groups <= 16) & (meta_file.max_len_group <= 62)]\n",
    "print(len(relevant_samples), \"relevant samples\")\n",
    "relevant_indices = pd.to_numeric(relevant_samples.id).tolist()\n",
    "relevant_indices\n",
    "encodings = []\n",
    "\n",
    "for i in relevant_indices:\n",
    "    try:\n",
    "        encoding = encode_icon(i)\n",
    "        encodings.append(encoding)\n",
    "    except: \n",
    "        print(\"encoding failed for sample with id=\",i)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58669"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encodings) # all samples succesfully encoded!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the pkl file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(datafolder, \"deepsvg_dense_representations/16g-62seq-128c-256z-encodings.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(encodings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}